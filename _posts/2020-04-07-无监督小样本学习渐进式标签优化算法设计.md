---
layout:     post
title:      无监督小样本学习渐进式标签优化算法设计
subtitle:   Unsupervised small sample learning
date:       2020-04-07
author:     JoselynZhao
header-img: img/post-bg-coffee.jpeg
catalog: true
tags:
    - 科研之路
---


# 基本思路
- 保留01标签
- 尽量避免采用错误标记数据进行训练，融入渐进式采样
- 用绝对距离取代相对距离



# 算法流程
## 基础设定
为了方便解释算法和画图演示，我们假设训练集共k类，k=3，每类有n个原始样本，n=2，每个原始样本增强c个样本，c=3.

也就是说，共3x2=6个样本簇，每个簇共3+1=4个样本，总共是6*4=24个样本。
目标：学习6个样本簇之间的同类关系。

## Input
正向阈值Kp，
负向阈值Kn，
标记阈值L

## 1 构建初始簇间标记矩阵

![image.png](http://note.youdao.com/yws/res/50221/WEBRESOURCE1967b876d93e031fdff23a5c4e1c4bc5) 图1

如上图所示，初始簇间标记矩阵对角线为1，其余为0.
由于同簇内各个样本的标记相同，这里就不用细分到样本级，直接用簇作为基本单位。

## 2 采用正样本对进行初始训练
图1中红色方块表示入选框，先选出所有的正样本对用于模型训练， 保证模型初期不学习错误知识。

## 3 提取24个样本的特征构成特征空间
理想情况下形成6个簇

## 4 计算簇内距离di，i属于[0,5]
具体的计算方法可以考虑一下两种：
- 原始样本与增量样本之间距离最大值或者均值
- 簇内任意两个样本之间距离最大值或者均值

这个距离将作为度量簇间相似性的参考值。
理论上来说，di会随着训练迭代逐渐减小。

## 5 计算簇间正向关系得分矩阵和负向关系得分矩阵
![image.png](http://note.youdao.com/yws/res/50225/WEBRESOURCEb0d59b3f1aa42d2767c5652d4157091e)图2

我们用s_ij表示第i簇的第j个样本。
di表示第i簇的簇内距离。
对于任意j属于[0,3], 我们统计距离它Kp*di范围之内的其他簇的样本个数NNij（这是一个列表）.
然后对簇i内所有的NNij进行求和（求平均也行），得到NNi作为正向得分（NNi仍是列表）。

同理，我们统计距离s_ij Kn*di范围之外的其他簇的样本个数NNij，并对簇内各样本求和，得到NNi作为负向得分。

对每个簇都执行上述操作，可得到正向关系得分矩阵和负向关系得分矩阵。

## 6 计算关系得分并修改标记矩阵
![image.png](http://note.youdao.com/yws/res/50223/WEBRESOURCE252acd155f9f156f32873d8abe9ff172)图3

正向关系得分矩阵和负向关系得分矩阵都形如图3所示。
在正向关系得分矩阵中，数字越大 簇间相似程度越大，
在负向关系得分矩阵中，数字越大，簇间相似程度越小。
下面计算关系得分R-score。
我们关心两个东西，一个关系得分矩阵对角线两侧数字的大小，我们用均值或求和都行，正向关系矩阵中，这个值越大，这两个簇属于同一类的可能性更大。同时，我们还关心两侧数字的方差，因为初期模型是不可靠的，如果A很像B，但B一点都不像A，无疑是降低了得分的置信度的。所以R-score应该通过mean和std两部分来计算，最简单的形式是R-score= mean-std。
如果R-score>标记阈值L。 则修改标记距离。 对于正向关系得分，我们将原来初定的0改为1，并做入选标记（打红框），对于负向关系得分，我们保留原来的0标记，并做入选标记。

## 7 用入选的样本对来进行模型训练
训练的样本对会越来越多，应用了渐进学习模式

## 8 重复步骤3-步骤6.
逐渐加入更多的样本进行反复训练，直到最后所有的样本对都加入训练。
在这个迭代的过程中，标记阈值L可以渐进变化，理论上来说，标记阈值一开始只允许少量最可靠的数据通过，而后续模型能力上升，可逐渐加量。所以L理论上说 应该从大到小进行变化。

同理，Kn和Kp也可以做适量的渐进变化，但一开始，Kp和kn要使得得分矩阵中大多数数值都为0.



